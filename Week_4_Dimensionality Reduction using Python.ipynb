{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 25\n\n# Calculate the price from the quantity sold and revenue\nsales_df['price'] = sales_df['revenue']/sales_df['quantity']\n\n# Drop the quantity and revenue features\nreduced_df = sales_df.drop(['quantity','revenue'], axis=1)\n\nprint(reduced_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 26\n\n# Calculate the mean height\nheight_df['height'] = height_df[['height_1','height_2','height_3']].mean(axis=1)\n\n# Drop the 3 original height features\nreduced_df = height_df.drop(['height_1','height_2','height_3'], axis=1)\n\nprint(reduced_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 27\n\n# Create a pairplot to inspect ansur_df\nsns.pairplot(ansur_df)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 28\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Scale the data\nscaler = StandardScaler()\nansur_std = scaler.fit_transform(ansur_df)\n\n# Apply PCA\npca = PCA()\npca.fit(ansur_std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 29\n\n# Inspect the explained variance ratio per component\nprint(pca.explained_variance_ratio_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 30\n\n# Build the pipeline\npipe = Pipeline([('scaler', StandardScaler()),\n        \t\t ('reducer', PCA(n_components=2))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 31\n\n# Build the pipeline\npipe = Pipeline([('scaler', StandardScaler()),\n                 ('reducer', PCA(n_components=2))])\n\n# Fit the pipeline to poke_df and transform the data\npc = pipe.fit_transform(poke_df)\n\nprint(pc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 32\n\n# Build the pipeline\npipe = Pipeline([\n        ('scaler', StandardScaler()),\n        ('reducer', PCA(n_components=2)),\n        ('classifier', RandomForestClassifier(random_state=0))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 33\n\n# Pipe a scaler to PCA selecting 80% of the variance\npipe = Pipeline([('scaler', StandardScaler()),\n        \t\t ('reducer', PCA(n_components=0.8))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 34\n\n# Pipeline a scaler and PCA selecting 10 components\npipe = Pipeline([('scaler', StandardScaler()),\n        \t\t ('reducer', PCA(n_components=10))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 35\n\n# Plot the MNIST sample data\nplot_digits(X_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}